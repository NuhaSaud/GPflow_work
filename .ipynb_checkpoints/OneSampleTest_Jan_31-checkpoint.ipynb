{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Sample test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuha BinTayyash, 2020\n",
    "\n",
    "This notebook shows one smaple test likelihood ratio with the gpflow 2 commit id = bd1e9c04b48dd5ccca9619d5eaa2595a358bdb08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn import metrics\n",
    "from scipy.signal import savgol_filter\n",
    "import scipy.stats as ss\n",
    "warnings.filterwarnings('ignore')\n",
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version: 2.1.0\n",
      "GPflow version: 2.0.0rc1\n"
     ]
    }
   ],
   "source": [
    "print('tensorflow version:',tf.__version__)\n",
    "print('GPflow version:',gpflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('time_points.csv',index_col=[0])\n",
    "X = X.values.astype(float) # time points \n",
    "X = X.reshape([-1,1])\n",
    "Y =  pd.read_csv('high_counts_high_dispersion.csv',index_col=[0])\n",
    "genes_name = Y.index.values.tolist() # genes name\n",
    "Y = Y.values.astype(int) # gene expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_posterior_predictive_distribution(xtest,model):\n",
    "        \n",
    "        var = []\n",
    "        f_samples = []\n",
    "        for i in range(20):\n",
    "            f_samples.append(model.predict_f_samples(xtest, 10))\n",
    "            f = np.vstack(f_samples)\n",
    "            link_f = np.exp(f[:, :, 0])\n",
    "            y = []\n",
    "            link_f_mean = np.mean(link_f, 0)\n",
    "            for i in range(link_f_mean.shape[0]):\n",
    "                y.append(ss.poisson.rvs(link_f_mean[i], size = 500)) \n",
    "            y = np.vstack(y)\n",
    "            var.append(y.T)\n",
    "\n",
    "        var = np.vstack(var)\n",
    "        mean = savgol_filter(np.mean(var,axis = 0), int(xtest.shape[0]/2)+1, 3)\n",
    "        mean = [(i > 0) * i for i in mean]\n",
    "        return mean,var\n",
    "# Hyper-parameters initialization\n",
    "def init_hyper_parameters(seed_value):\n",
    "    hyper_parameters = {}   \n",
    "    hyper_parameters['ls'] = np.random.uniform(0. , (np.max(X)-np.min(X))/10.)    \n",
    "    hyper_parameters['var'] = np.random.uniform(1., 20.)\n",
    "    \n",
    "    if model_index == 2:\n",
    "        hyper_parameters['ls'] = 1000. # constant kernel\n",
    "\n",
    "    tf.compat.v1.get_default_graph()\n",
    "    tf.compat.v1.set_random_seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "    gpflow.config.set_default_float(np.float64)\n",
    "    \n",
    "    return hyper_parameters\n",
    "\n",
    "# fit a GP and fix Cholesky decomposition failure,optimization failure and bad solution \n",
    "# by random initialization if detected  \n",
    "\n",
    "def fit_GP(count_fix,lik_name):\n",
    "    np.random.seed(count_fix)\n",
    "    hyper_parameters = init_hyper_parameters(count_fix)\n",
    "    fit_successed = True   \n",
    "    try:\n",
    "        # select RBF kernel or constant kernel\n",
    "        if hyper_parameters['ls'] == 1000:\n",
    "            kern = gpflow.kernels.Constant(variance= hyper_parameters['var']) \n",
    "        else:\n",
    "            kern = gpflow.kernels.RBF( variance= hyper_parameters['var'],lengthscale = hyper_parameters['ls'])     \n",
    "        \n",
    "        y = Y[i].astype(float)\n",
    "        y = y.reshape([-1,1])\n",
    "        if lik_name == 'Gaussian':\n",
    "            y = np.log(y+1)\n",
    "            model = gpflow.models.GPR((X, y), kern)\n",
    "            model = gpflow.models.GPR((X, y), kern)\n",
    "        else:\n",
    "            model = gpflow.models.VGP((X,y), kernel= kern,likelihood= gpflow.likelihoods.Poisson())\n",
    "        \n",
    "        @tf.function(autograph=False)\n",
    "        def objective():\n",
    "            return - model.log_marginal_likelihood()\n",
    "       \n",
    "        o = gpflow.optimizers.Scipy()\n",
    "        res = o.minimize(objective, variables=model.trainable_variables)\n",
    "        \n",
    "        if not(res.success):\n",
    "            if count_fix < 10:\n",
    "                print('Optimization fail.')\n",
    "                count_fix = count_fix +1 \n",
    "                fit_successed,model = fit_GP(count_fix,lik_name)\n",
    "            else:\n",
    "                print('Can not fit a Gaussian process, Optimization fail.')\n",
    "                fit_successed = False\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        if count_fix < 10:\n",
    "            print('Cholesky decomposition was not successful.')\n",
    "            count_fix = count_fix +1 \n",
    "            fit_successed,model = fit_GP(count_fix,lik_name)\n",
    "        else:\n",
    "            print('Can not fit a Gaussian process, Cholesky decomposition was not successful.')\n",
    "            fit_successed = False\n",
    "\n",
    "    if fit_successed:\n",
    "        xtest = np.linspace(np.min(X),np.max(X),100)[:,None]\n",
    "        if lik_name == 'Gaussian':\n",
    "            mean, var = model.predict_y(xtest)\n",
    "            mean = mean.numpy()\n",
    "            var = var.numpy()\n",
    "        else:\n",
    "            # mean of posterior predictive samples\n",
    "            mean,var = samples_posterior_predictive_distribution(xtest,model)         \n",
    "        \n",
    "        \n",
    "        if count_fix < 5: # limit number of trial to fix bad solution \n",
    "            y_mean = np.mean(y)\n",
    "            mean_mean = np.mean(mean) \n",
    "            \n",
    "            if y_mean > 0.0:\n",
    "                if abs(round((mean_mean-y_mean)/y_mean)) > 0 or mean_mean == 0.0:\n",
    "                    print('local Optima')\n",
    "                    print(model_index)\n",
    "                    print('y_mean',y_mean)\n",
    "                    print('mean_mean',mean_mean)\n",
    "                    print('abs(round((mean_mean-y_mean)/y_mean))',abs(round((mean_mean-y_mean)/y_mean)))\n",
    "                    count_fix = count_fix +1 \n",
    "                    fit_successed,model = fit_GP(count_fix,lik_name)\n",
    "\n",
    "    return fit_successed,model\n",
    "\n",
    "def fit_model(lik_name):\n",
    "    count_fix = 0\n",
    "    fit_successed,model = fit_GP(count_fix,lik_name)\n",
    "\n",
    "    if fit_successed:\n",
    "        log_likelihood = model.log_marginal_likelihood().numpy()\n",
    "        ckpt = tf.train.Checkpoint(model= model, step=tf.Variable(1))\n",
    "        dir_name = 'models/'\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "        filename = dir_name+genes_name[i]+'_model_'+str(model_index)\n",
    "        ckpt.write(filename)\n",
    "\n",
    "    else:\n",
    "        log_likelihood = np.nan  # set to Nan in case of Cholesky decomposition failure or optimization failure \n",
    "        model = None\n",
    "    return log_likelihood,model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 16/360 [00:10<03:34,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 53/360 [00:35<03:58,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n",
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 87/360 [01:02<02:55,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 265/360 [03:33<01:27,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 283/360 [04:03<02:11,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n",
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 355/360 [05:26<00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cholesky decomposition was not successful.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 360/360 [05:31<00:00,  1.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dynamic_model_log_likelihood</th>\n",
       "      <th>Constant_model_log_likelihood</th>\n",
       "      <th>log_likelihood_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gene_1</th>\n",
       "      <td>-37.574788</td>\n",
       "      <td>-42.269266</td>\n",
       "      <td>4.694478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_2</th>\n",
       "      <td>-21.127415</td>\n",
       "      <td>-21.127412</td>\n",
       "      <td>-0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_3</th>\n",
       "      <td>-37.914913</td>\n",
       "      <td>-37.508437</td>\n",
       "      <td>-0.406476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_4</th>\n",
       "      <td>-20.675635</td>\n",
       "      <td>-20.675634</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_5</th>\n",
       "      <td>-34.471219</td>\n",
       "      <td>-42.191281</td>\n",
       "      <td>7.720062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_356</th>\n",
       "      <td>-20.323807</td>\n",
       "      <td>-20.494668</td>\n",
       "      <td>0.170861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_357</th>\n",
       "      <td>-39.783372</td>\n",
       "      <td>-42.442096</td>\n",
       "      <td>2.658723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_358</th>\n",
       "      <td>-11.997632</td>\n",
       "      <td>-11.997737</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_359</th>\n",
       "      <td>-35.116495</td>\n",
       "      <td>-38.247876</td>\n",
       "      <td>3.131381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_360</th>\n",
       "      <td>-11.745407</td>\n",
       "      <td>-12.180920</td>\n",
       "      <td>0.435512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dynamic_model_log_likelihood  Constant_model_log_likelihood  \\\n",
       "gene_1                      -37.574788                     -42.269266   \n",
       "gene_2                      -21.127415                     -21.127412   \n",
       "gene_3                      -37.914913                     -37.508437   \n",
       "gene_4                      -20.675635                     -20.675634   \n",
       "gene_5                      -34.471219                     -42.191281   \n",
       "...                                ...                            ...   \n",
       "gene_356                    -20.323807                     -20.494668   \n",
       "gene_357                    -39.783372                     -42.442096   \n",
       "gene_358                    -11.997632                     -11.997737   \n",
       "gene_359                    -35.116495                     -38.247876   \n",
       "gene_360                    -11.745407                     -12.180920   \n",
       "\n",
       "          log_likelihood_ratio  \n",
       "gene_1                4.694478  \n",
       "gene_2               -0.000002  \n",
       "gene_3               -0.406476  \n",
       "gene_4               -0.000001  \n",
       "gene_5                7.720062  \n",
       "...                        ...  \n",
       "gene_356              0.170861  \n",
       "gene_357              2.658723  \n",
       "gene_358              0.000105  \n",
       "gene_359              3.131381  \n",
       "gene_360              0.435512  \n",
       "\n",
       "[360 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_log_likelihoods = {}\n",
    "lik_name = 'Gaussian'\n",
    "column_name = ['Dynamic_model_log_likelihood','Constant_model_log_likelihood','log_likelihood_ratio']\n",
    "for i in tqdm(range(Y.shape[0])):\n",
    "    model_index = 1 #dynamic model GP with RBF kernel  \n",
    "    model_1_log_likelihood,model = fit_model(lik_name)\n",
    "     \n",
    "    if not(np.isnan(model_1_log_likelihood)):\n",
    "        ls = model.kernel.lengthscale.numpy()\n",
    "\n",
    "    model_index = 2 #constant model GP with constant kernel \n",
    "    model_2_log_likelihood,model = fit_model(lik_name)\n",
    "\n",
    "    if np.isnan(model_1_log_likelihood) or np.isnan(model_2_log_likelihood):\n",
    "            ll_ratio = np.nan\n",
    "    else:              \n",
    "        #test local optima case 2\n",
    "        ll_ratio = model_1_log_likelihood - model_2_log_likelihood\n",
    "        if (ls < ((np.max(X)-np.min(X))/10.) and round(ll_ratio) <= 0):\n",
    "            model_index = 1 #dynamic model GP with RBF kernel  \n",
    "            model_1_log_likelihood,model = fit_model(lik_name)\n",
    "     \n",
    "            if not(np.isnan(model_1_log_likelihood)):\n",
    "                ls = model.kernel.lengthscale.numpy()\n",
    "\n",
    "            model_index = 2 #constant model GP with constant kernel \n",
    "            model_2_log_likelihood,model = fit_model(lik_name)\n",
    "\n",
    "        ll_ratio = model_1_log_likelihood - model_2_log_likelihood\n",
    "\n",
    "    log_likelihood =  [model_1_log_likelihood,model_2_log_likelihood,ll_ratio]                           \n",
    "\n",
    "    genes_log_likelihoods[genes_name[i]] = log_likelihood\n",
    "\n",
    "  \n",
    "log_likelihood_ratio = pd.DataFrame.from_dict(genes_log_likelihoods, orient='index', columns= column_name)\n",
    "log_likelihood_ratio.to_csv('log_likelihood_ratio_Jan_31_'+lik_name+'.csv')\n",
    "log_likelihood_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv_1]",
   "language": "python",
   "name": "conda-env-myenv_1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
